{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import requests\n",
    "import zipfile\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading the Medicare Hospital Compare Data\n",
    "\n",
    "url = 'https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1? \\\n",
    "       content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip'\n",
    "request = requests.get(url)\n",
    "file = zipfile.ZipFile(io.BytesIO(request.content))\n",
    "file.extractall('staging')\n",
    "\n",
    "# UTF-8 conversion\n",
    "\n",
    "files = glob.glob(os.path.join(\"staging\" + \"/*.csv\"))\n",
    "\n",
    "dict_ = {}\n",
    "for filename in files:\n",
    "    if filename == 'Hospital.pdf' or filename == 'readme.txt' or filename.endswith(\n",
    "            'zip') or filename == 'FY2015_Percent_Change_in_Medicare_Payments.csv':\n",
    "        print(filename)\n",
    "    else:\n",
    "        dict_[filename] = pd.read_csv(filename, header=0, encoding='cp1252').dropna(axis=1, how='all')\n",
    "\n",
    "for file in dict_:\n",
    "    dict_[file].to_csv(file, encoding='utf-8')\n",
    "\n",
    "dir_path = os.path.abspath(os.path.realpath(\"staging\"))\n",
    "dir_path = dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "## Creating the Database\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    try:\n",
    "        con = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "\n",
    "create_connection(\"medicare_hospital_compare_1.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rushabh Shah\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1345: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# creating the tables from CSV\n",
    "\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "\n",
    "    if filename == 'Hospital.pdf' or filename == 'readme.txt' or filename.endswith(\n",
    "            'zip') or filename == 'FY2015_Percent_Change_in_Medicare_Payments.csv':\n",
    "        continue\n",
    "    else:\n",
    "        filepath = dir_path + \"\\\\\" + filename\n",
    "        con = sqlite3.connect(\"medicare_hospital_compare_1.db\")\n",
    "        c = con.cursor()\n",
    "        with open(filepath, 'rt', encoding=\"utf8\") as fin:\n",
    "            filename = filename.lower()\n",
    "            filename = filename.replace(\"-\", \"_\")\n",
    "            filename = filename.replace(\" \", \"_\")\n",
    "            filename = filename.replace(\"/\", \"_\")\n",
    "            filename = filename.replace(\"%\", \"pct\")\n",
    "            filename = filename.replace(\".csv\", \"\")\n",
    "            if filename[0].isalpha():\n",
    "                filename = filename\n",
    "            else:\n",
    "                filename = \"t_\" + filename\n",
    "            dr = csv.reader(fin)  # comma is default delimiter\n",
    "            row1 = next(dr)\n",
    "            column_count = len(list(list(dr)[0]))\n",
    "            CR = \"DROP TABLE IF EXISTS filename;\"\n",
    "            create_table_statement = \"CREATE TABLE IF NOT EXISTS \" + filename + \" (\"\n",
    "            for i in range(0, column_count):\n",
    "                row1[i] = row1[i].lower()\n",
    "                row1[i] = row1[i].replace(\"-\", \"_\")\n",
    "                row1[i] = row1[i].replace(\" \", \"_\")\n",
    "                row1[i] = row1[i].replace(\"/\", \"_\")\n",
    "                row1[i] = row1[i].replace(\"%\", \"pct\")\n",
    "\n",
    "                if row1[i][:1].isalpha():\n",
    "                    row1[i] = row1[i]\n",
    "                else:\n",
    "                    row1[i] = \"c_\" + row1[i]\n",
    "\n",
    "                create_table_statement = create_table_statement + '{} text,'.format(row1[i])\n",
    "            create_table_statement = create_table_statement[:-1] + ');'\n",
    "            c.execute(CR)\n",
    "            c.execute(create_table_statement)\n",
    "\n",
    "            df = pd.read_csv(filepath, header=0)\n",
    "            df.to_sql(filename, con, if_exists='replace', dtype=\"text\", index=False)\n",
    "\n",
    "            con.commit()\n",
    "            c.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rushabh Shah\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1345: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "## Downloding hospital_ranking_focus_states\n",
    "\n",
    "\n",
    "import requests\n",
    "import openpyxl\n",
    "\n",
    "url = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\"\n",
    "r = requests.get(url)\n",
    "r.headers\n",
    "xf = open(\"hospital_ranking_focus_states.xlsx\",\"wb\")\n",
    "xf.write(r.content)\n",
    "xf.close()\n",
    "wb = openpyxl.load_workbook(\"hospital_ranking_focus_states.xlsx\")\n",
    "    \n",
    "filename=\"hospital_ranking_focus_states.xlsx\" \n",
    "con=sqlite3.connect(\"medicare_hospital_compare_1.db\")\n",
    "wb=pd.read_excel(filename,sheetname=None)\n",
    "for sheet in wb:\n",
    "    wb[sheet].to_sql(sheet,con, index=False)\n",
    "con.commit()\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##  Creating a hospital ranking MS Excel Workbook named “hospital_ranking.xlsx”\n",
    "\n",
    "import openpyxl\n",
    "wb = openpyxl.Workbook()\n",
    "sheet_1 = wb.create_sheet(\"Nationwide\")\n",
    "sheet_1.cell(row = 1, column = 1, value = \"Provider ID\")\n",
    "sheet_1.cell(row = 1, column = 2, value = \"Hospital Name\")\n",
    "sheet_1.cell(row = 1, column = 3, value = \"City\")\n",
    "sheet_1.cell(row = 1, column = 4, value = \"State\")\n",
    "sheet_1.cell(row = 1, column = 5, value = \"County\")\n",
    "wb.save(\"hospital_ranking.xlsx\")\n",
    "\n",
    "\n",
    "##importing data to hospital_ranking excel file\n",
    "\n",
    "con = sqlite3.connect(\"medicare_hospital_compare_1.db\")\n",
    "c = con.cursor()\n",
    "selecting_data = \"select g.[Provider ID], g.[Hospital Name], g.City, g.State, g.[County Name] as 'County' from hospital_general_information as g inner join [Hospital National Ranking] as h on g.[Provider ID] = h.[Provider ID] order by h.Ranking limit 100;\"\n",
    "df = pd.read_sql(selecting_data, con)\n",
    "\n",
    "writer = pd.ExcelWriter('hospital_ranking.xlsx')\n",
    "df.to_excel(writer, sheet_name ='Nationwide', index= False)\n",
    "####writer.save()\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating the state wise sheet \n",
    "\n",
    "wb = openpyxl.load_workbook(\"hospital_ranking_focus_states.xlsx\")\n",
    "sheet_2_name = wb.get_sheet_names()[1]\n",
    "sheet_2 = wb.get_sheet_by_name(sheet_2_name)\n",
    "i = 2\n",
    "state=[]\n",
    "abstate=[]\n",
    "while sheet_2.cell(row = i, column = 1).value != None:\n",
    "    state.append(sheet_2.cell(row = i,column = 1).value)\n",
    "    abstate.append(sheet_2.cell(row = i, column = 2).value)\n",
    "    i += 1\n",
    "state.sort()\n",
    "abstate.sort()\n",
    "abstate\n",
    "wb.close()\n",
    "\n",
    "con = sqlite3.connect(\"medicare_hospital_compare_1.db\")\n",
    "c = con.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Creating the state wise sheet\n",
    "\n",
    "\n",
    "wb = openpyxl.load_workbook(\"hospital_ranking.xlsx\")\n",
    "for states in state: \n",
    "    sheet_1 = wb.create_sheet(states)\n",
    "    sheet_1.cell(row = 1, column = 1, value = \"Provider ID\")\n",
    "    sheet_1.cell(row = 1, column = 2, value = \"Hospital Name\")\n",
    "    sheet_1.cell(row = 1, column = 3, value = \"City\")\n",
    "    sheet_1.cell(row = 1, column = 4, value = \"State\")\n",
    "    sheet_1.cell(row = 1, column = 5, value = \"County\")\n",
    "wb.save(\"hospital_ranking.xlsx\")\n",
    "    \n",
    "   \n",
    "\n",
    "##Adding the data to newly state sheet\n",
    "count = 0     \n",
    "#con = sqlite3.connect(\"medicare_hospital_compare_1.db\")\n",
    "#c = con.cursor()\n",
    "####writer = pd.ExcelWriter('hospital_ranking.xlsx')\n",
    "for states in state:\n",
    "    \n",
    "    selecting_data = \"select g.[Provider ID], g.[Hospital Name], g.City, g.State, g.[County Name] as 'County' from hospital_general_information as g inner join [Hospital National Ranking] as h on g.[Provider ID] = h.[Provider ID] where g.State= \" + \"'\" + abstate[count] + \"'\" + \" order by h.Ranking limit 100;\"\n",
    "    df = pd.read_sql(selecting_data, con)\n",
    "    \n",
    "    df.to_excel(writer, sheet_name = states, index=False)\n",
    "    count = count + 1\n",
    "\n",
    "writer.save()\n",
    "writer.close()\n",
    "wb.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the Measure\n",
    "\n",
    "data=\"select State, [Measure ID], [Measure Name], Score from  timely_and_effective_care___hospital  where length(Score) < 7 order by [Measure ID];\"\n",
    "df = pd.read_sql(data, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Score']= df['Score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = df.groupby('Measure ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measure ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ED_1b</th>\n",
       "      <td>103.307105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ED_2b</th>\n",
       "      <td>64.940604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMM_2</th>\n",
       "      <td>13.170603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMM_3_OP_27_FAC_ADHPCT</th>\n",
       "      <td>14.878308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_1</th>\n",
       "      <td>6.737422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_18b</th>\n",
       "      <td>43.567914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_2</th>\n",
       "      <td>21.479484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_20</th>\n",
       "      <td>18.346156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_21</th>\n",
       "      <td>18.477840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_22</th>\n",
       "      <td>1.767389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_23</th>\n",
       "      <td>18.821828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_29</th>\n",
       "      <td>24.513163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_30</th>\n",
       "      <td>19.291772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_31</th>\n",
       "      <td>29.526283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_3b</th>\n",
       "      <td>36.653652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_4</th>\n",
       "      <td>6.241242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_5</th>\n",
       "      <td>5.310821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC_01</th>\n",
       "      <td>4.464330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STK_4</th>\n",
       "      <td>15.438288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTE_5</th>\n",
       "      <td>11.632315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTE_6</th>\n",
       "      <td>4.507817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Score\n",
       "Measure ID                        \n",
       "ED_1b                   103.307105\n",
       "ED_2b                    64.940604\n",
       "IMM_2                    13.170603\n",
       "IMM_3_OP_27_FAC_ADHPCT   14.878308\n",
       "OP_1                      6.737422\n",
       "OP_18b                   43.567914\n",
       "OP_2                     21.479484\n",
       "OP_20                    18.346156\n",
       "OP_21                    18.477840\n",
       "OP_22                     1.767389\n",
       "OP_23                    18.821828\n",
       "OP_29                    24.513163\n",
       "OP_30                    19.291772\n",
       "OP_31                    29.526283\n",
       "OP_3b                    36.653652\n",
       "OP_4                      6.241242\n",
       "OP_5                      5.310821\n",
       "PC_01                     4.464330\n",
       "STK_4                    15.438288\n",
       "VTE_5                    11.632315\n",
       "VTE_6                     4.507817"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.min()\n",
    "group.max()\n",
    "group.mean()\n",
    "group.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_statistics = (group.agg([np.min, np.max, np.mean, np.std]).rename(columns={'amin':'Minimum','amax': 'Maximum','mean': 'Average','std': 'Standard Deviation'}))\n",
    "statistics = df_statistics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range (0,len(statistics)):\n",
    "    data.append(statistics.iloc[i].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_stat = pd.DataFrame(data)\n",
    "m_stat.reset_index(inplace = True)\n",
    "m_stat.drop('index', axis =1)\n",
    "m_stat.columns = ['Measure ID','Minimum','Maximum','Average','Standard Deviation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_stat['Measure Name'] = m_stat['Measure ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_stat = m_stat[['Measure ID','Measure Name','Minimum', 'Maximum','Average', 'Standard Deviation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "excel_writer = pd.ExcelWriter('measure_statistics.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "final_stat.to_excel(excel_writer, sheet_name = 'Nationwide', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating state wise measure\n",
    "count=0\n",
    "for states in state:\n",
    "    data=\"select State, [Measure ID], [Measure Name], Score from  timely_and_effective_care___hospital  where length(Score) < 7 and State= \" + \"'\" + abstate[count] + \"'\" + \"order by [Measure ID];\"\n",
    "    df = pd.read_sql(data, con)\n",
    "    df['Score']= df['Score'].astype(float)\n",
    "    group = df.groupby('Measure ID')\n",
    "    df_statistics = (group.agg([np.min, np.max, np.mean, np.std]).rename(columns={'amin':'Minimum','amax': 'Maximum','mean': 'Average','std': 'Standard Deviation'}))\n",
    "    statistics = df_statistics.copy()\n",
    "    data = []\n",
    "    for i in range (0,len(statistics)):\n",
    "        data.append(statistics.iloc[i].reset_index(drop = True))\n",
    "    m_stat = pd.DataFrame(data)\n",
    "    m_stat.reset_index(inplace = True)\n",
    "    m_stat.drop('index', axis =1)\n",
    "    m_stat.columns = ['Measure ID','Minimum','Maximum','Average','Standard Deviation']\n",
    "    m_stat['Measure Name'] = m_stat['Measure ID']\n",
    "    final_stat = m_stat[['Measure ID','Measure Name','Minimum', 'Maximum','Average', 'Standard Deviation']]\n",
    "    #final_stat.to_excel()\n",
    "    final_stat.to_excel(excel_writer, sheet_name = states, index = False)\n",
    "    count = count + 1\n",
    "excel_writer.save()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
